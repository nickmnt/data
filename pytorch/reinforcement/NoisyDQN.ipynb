{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRY132TIJIs4Bmq99enPun",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74d5021f1dcf4d32900de5bafe64e4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67a960dd90fd402aba3b901a236d3693",
              "IPY_MODEL_7f04eb1c54bf45c0b531fc74d92110cb",
              "IPY_MODEL_b82042eeb8864296a5ee3c1cc982b40f"
            ],
            "layout": "IPY_MODEL_22b51320b16544a48351900f5694bf98"
          }
        },
        "67a960dd90fd402aba3b901a236d3693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b10d7ce9f4346eab271614cf0815fda",
            "placeholder": "​",
            "style": "IPY_MODEL_5b22f931325d43b6819f5287b5e99333",
            "value": "Epoch 7: "
          }
        },
        "7f04eb1c54bf45c0b531fc74d92110cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9fe6eb7e2d04fb3a3665f203312ac3b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76ce04c73cec468589d5fa9348e79b6d",
            "value": 1
          }
        },
        "b82042eeb8864296a5ee3c1cc982b40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce6fb78e724b4e958ad4b4d8da47f7d9",
            "placeholder": "​",
            "style": "IPY_MODEL_4cb940add6eb4d87a9d1dec1d5018042",
            "value": " 4/? [00:40&lt;00:00, 10.24s/it, loss=0.00369, v_num=0]"
          }
        },
        "22b51320b16544a48351900f5694bf98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6b10d7ce9f4346eab271614cf0815fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b22f931325d43b6819f5287b5e99333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9fe6eb7e2d04fb3a3665f203312ac3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ce04c73cec468589d5fa9348e79b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce6fb78e724b4e958ad4b4d8da47f7d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb940add6eb4d87a9d1dec1d5018042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimamt/machine_learning/blob/master/pytorch/reinforcement/NoisyDQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y xvfb\n",
        "\n",
        "!pip install pygame gym==0.18 stable-baselines3 pytorch-lightning==1.6.0 pyvirtualdisplay\n",
        "\n",
        "!pip install git+https://github.com/GrupoTuring/PyGame-Learning-Environment\n",
        "!pip install git+https://github.com/lusob/gym-ple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YP7j4g6laJ0",
        "outputId": "db8b407d-6b3d-413a-c6f9-99b099b37851"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.20.13-1ubuntu1~20.04.6).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-510\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.8/dist-packages (2.1.3)\n",
            "Requirement already satisfied: gym==0.18 in /usr/local/lib/python3.8/dist-packages (0.18.0)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.8/dist-packages (1.4.0)\n",
            "Requirement already satisfied: pytorch-lightning==1.6.0 in /usr/local/lib/python3.8/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.8/dist-packages (3.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.18) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from gym==0.18) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from gym==0.18) (1.7.3)\n",
            "Requirement already satisfied: Pillow<=7.2.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.18) (7.1.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from gym==0.18) (1.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (4.5.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (4.64.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (23.0)\n",
            "Requirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (0.3.2)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (2023.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (6.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (2.11.2)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.0) (1.13.1+cu116)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from stable-baselines3) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from stable-baselines3) (3.2.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (3.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.25.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.18) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.0.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.19.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.51.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (57.4.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (2.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->stable-baselines3) (2022.7.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (3.0.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/GrupoTuring/PyGame-Learning-Environment\n",
            "  Cloning https://github.com/GrupoTuring/PyGame-Learning-Environment to /tmp/pip-req-build-3ifn7wlj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/GrupoTuring/PyGame-Learning-Environment /tmp/pip-req-build-3ifn7wlj\n",
            "  Resolved https://github.com/GrupoTuring/PyGame-Learning-Environment to commit 52ace013e3ea2fe5df08df98ec4dda902801e9df\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ple==0.0.2) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from ple==0.0.2) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/lusob/gym-ple\n",
            "  Cloning https://github.com/lusob/gym-ple to /tmp/pip-req-build-a2mi9p5b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lusob/gym-ple /tmp/pip-req-build-a2mi9p5b\n",
            "  Resolved https://github.com/lusob/gym-ple to commit 7cedbf4e31be86f5ca2aae5c0dfd9d38825af64e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WVCsLKok7-b",
        "outputId": "9086b65b-0bfc-427c-a099-5200758ad078"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f3ecf436100>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "Display(visible=False, size=(1400, 900)).start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "import random\n",
        "import gym\n",
        "import gym_ple\n",
        "import matplotlib\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "from collections import deque, namedtuple\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import IterableDataset\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "\n",
        "from gym.wrappers import TransformObservation\n",
        "\n",
        "from stable_baselines3.common.atari_wrappers import MaxAndSkipEnv, WarpFrame\n",
        "\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "num_gpus = torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "7UpQ8JO0ls9s"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copied from: https://colab.research.google.com/github/deepmind/dm_control/blob/master/tutorial.ipynb#scrollTo=gKc1FNhKiVJX\n",
        "\n",
        "def display_video(frames, framerate=30):\n",
        "  height, width, _ = frames[0].shape\n",
        "  dpi = 70\n",
        "  orig_backend = matplotlib.get_backend()\n",
        "  matplotlib.use('Agg')\n",
        "  fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n",
        "  matplotlib.use(orig_backend)\n",
        "  ax.set_axis_off()\n",
        "  ax.set_aspect('equal')\n",
        "  ax.set_position([0, 0, 1, 1])\n",
        "  im = ax.imshow(frames[0])\n",
        "  def update(frame):\n",
        "    im.set_data(frame)\n",
        "    return [im]\n",
        "  interval = 1000/framerate\n",
        "  anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
        "                                  interval=interval, blit=True, repeat=False)\n",
        "  return HTML(anim.to_html5_video())"
      ],
      "metadata": {
        "id": "O9SH1Bc-luwj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from torch.nn.init import kaiming_uniform_, zeros_\n",
        "\n",
        "class NoisyLinear(nn.Module):\n",
        "\n",
        "  def __init__(self, in_features, out_features, sigma):\n",
        "    super(NoisyLinear, self).__init__()\n",
        "\n",
        "    self.w_mu = nn.Parameter(torch.empty((out_features, in_features)))\n",
        "    self.w_sigma = nn.Parameter(torch.empty((out_features, in_features)))\n",
        "    self.b_mu = nn.Parameter(torch.empty((out_features)))\n",
        "    self.b_sigma = nn.Parameter(torch.empty((out_features)))\n",
        "\n",
        "    kaiming_uniform_(self.w_mu, a=math.sqrt(5))    \n",
        "    kaiming_uniform_(self.w_sigma, a=math.sqrt(5)) \n",
        "    zeros_(self.b_mu)\n",
        "    zeros_(self.b_sigma)\n",
        "\n",
        "  def forward(self, x, sigma=0.5):\n",
        "    # Bigger sigma - More spread around - More noise\n",
        "    \n",
        "    if self.training:\n",
        "      w_noise = torch.normal(0, sigma, size=self.w_mu.size()).to(device)\n",
        "      b_noise = torch.normal(0, sigma, size=self.b_mu.size()).to(device)\n",
        "      return F.linear(x, self.w_mu + self.w_sigma * w_noise, \n",
        "                    self.b_mu + self.b_sigma * b_noise)\n",
        "    else:\n",
        "      return F.linear(x, self.w_mu, self.b_mu)"
      ],
      "metadata": {
        "id": "I82vS7dWlvgc"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size, obs_shape, n_actions, sigma=0.5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(obs_shape[0], 64, kernel_size=3),\n",
        "        nn.MaxPool2d(kernel_size=4),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 64, kernel_size=3),\n",
        "        nn.MaxPool2d(kernel_size=4),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    conv_out_size = self._get_conv_out(obs_shape)\n",
        "    self.head = nn.Sequential(\n",
        "        NoisyLinear(conv_out_size, hidden_size, sigma=sigma),\n",
        "        nn.ReLU(),\n",
        "        NoisyLinear(hidden_size, hidden_size, sigma=sigma),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    # Q(s, a) = V(s) + Adv(s, a)\n",
        "    self.fc_value = NoisyLinear(hidden_size, 1, sigma=sigma)\n",
        "    self.fc_adv = NoisyLinear(hidden_size, n_actions, sigma=sigma)\n",
        "\n",
        "  def _get_conv_out(self, shape):\n",
        "    conv_out = self.conv(torch.zeros(1, *shape))\n",
        "    return int(np.prod(conv_out.size()))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x.float()).view(x.size()[0], -1) # First arg is batch_size\n",
        "    x = self.head(x)\n",
        "    adv = self.fc_adv(x)\n",
        "    value = self.fc_value(x)\n",
        "    return value + adv - torch.mean(adv, dim=1, keepdim=True)"
      ],
      "metadata": {
        "id": "PLtUjy7Dlyis"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do not need an epsilon greedy method because the neural network will do the \n",
        "exploration."
      ],
      "metadata": {
        "id": "lR3FmKvzqYND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy(state, net):\n",
        "  state = torch.tensor([state]).to(device)\n",
        "  q_values = net(state)\n",
        "  action = q_values.argmax(dim=-1)\n",
        "  action = int(action.item())\n",
        "  return action"
      ],
      "metadata": {
        "id": "zp_v8MuLqVoL"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer: \n",
        "\n",
        "  def __init__(self, capacity):\n",
        "    super().__init__()\n",
        "    self.buffer = deque(maxlen=capacity) # Will automatically delete old entries\n",
        "    # to make room for new ones\n",
        "\n",
        "    # stores priorites of each of the samples contained in the buffer\n",
        "    self.priorities = deque(maxlen=capacity)\n",
        "\n",
        "    self.capacity = capacity\n",
        "\n",
        "    self.alpha = 1.0\n",
        "    self.beta = 0.5\n",
        "    self.max_priority = 0.0\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.buffer)\n",
        "\n",
        "  def append(self, experience):\n",
        "    self.buffer.append(experience)\n",
        "    self.priorities.append(self.max_priority)\n",
        "\n",
        "  def update(self, index, priority):\n",
        "    if priority > self.max_priority:\n",
        "      self.max_priority = priority\n",
        "    self.priorities[index] = priority \n",
        "  def sample(self, batch_size):\n",
        "    probs = np.array(self.priorities, dtype=np.float64) + 1e-4\n",
        "    probs = probs ** self.alpha\n",
        "    probs = probs / probs.sum()\n",
        "\n",
        "    weights = (self.__len__() * probs) ** -self.beta\n",
        "    weights = weights / weights.max()\n",
        "\n",
        "    idx = random.choices(range(self.__len__()), weights=probs, k=batch_size)\n",
        "    sample = [(i, weights[i], *self.buffer[i]) for i in idx]    \n",
        "    return sample"
      ],
      "metadata": {
        "id": "3KpzouyHqPOt"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RLDataset(IterableDataset):\n",
        "\n",
        "  def __init__(self, buffer, sample_size=200):\n",
        "    self.buffer = buffer\n",
        "    self.sample_size = sample_size\n",
        "\n",
        "  def __iter__(self):\n",
        "    for experience in self.buffer.sample(self.sample_size):\n",
        "      yield experience"
      ],
      "metadata": {
        "id": "akGlmU0wq5b7"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunningMeanStd:\n",
        "    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n",
        "    def __init__(self, epsilon=1e-4, shape=()):\n",
        "        self.mean = np.zeros(shape, \"float64\")\n",
        "        self.var = np.ones(shape, \"float64\")\n",
        "        self.count = epsilon\n",
        "\n",
        "    def update(self, x):\n",
        "        batch_mean = np.mean(x, axis=0)\n",
        "        batch_var = np.var(x, axis=0)\n",
        "        batch_count = x.shape[0]\n",
        "        self.update_from_moments(batch_mean, batch_var, batch_count)\n",
        "\n",
        "    def update_from_moments(self, batch_mean, batch_var, batch_count):\n",
        "        self.mean, self.var, self.count = update_mean_var_count_from_moments(\n",
        "            self.mean, self.var, self.count, batch_mean, batch_var, batch_count\n",
        "        )\n",
        "\n",
        "\n",
        "def update_mean_var_count_from_moments(\n",
        "    mean, var, count, batch_mean, batch_var, batch_count\n",
        "):\n",
        "    delta = batch_mean - mean\n",
        "    tot_count = count + batch_count\n",
        "\n",
        "    new_mean = mean + delta * batch_count / tot_count\n",
        "    m_a = var * count\n",
        "    m_b = batch_var * batch_count\n",
        "    M2 = m_a + m_b + np.square(delta) * count * batch_count / tot_count\n",
        "    new_var = M2 / tot_count\n",
        "    new_count = tot_count\n",
        "\n",
        "    return new_mean, new_var, new_count\n",
        "\n",
        "\n",
        "class NormalizeObservation(gym.core.Wrapper):\n",
        "    def __init__(\n",
        "        self,\n",
        "        env,\n",
        "        epsilon=1e-8,\n",
        "    ):\n",
        "        super().__init__(env)\n",
        "        self.num_envs = getattr(env, \"num_envs\", 1)\n",
        "        self.is_vector_env = getattr(env, \"is_vector_env\", False)\n",
        "        if self.is_vector_env:\n",
        "            self.obs_rms = RunningMeanStd(shape=self.single_observation_space.shape)\n",
        "        else:\n",
        "            self.obs_rms = RunningMeanStd(shape=self.observation_space.shape)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, rews, dones, infos = self.env.step(action)\n",
        "        if self.is_vector_env:\n",
        "            obs = self.normalize(obs)\n",
        "        else:\n",
        "            obs = self.normalize(np.array([obs]))[0]\n",
        "        return obs, rews, dones, infos\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        return_info = kwargs.get(\"return_info\", False)\n",
        "        if return_info:\n",
        "            obs, info = self.env.reset(**kwargs)\n",
        "        else:\n",
        "            obs = self.env.reset(**kwargs)\n",
        "        if self.is_vector_env:\n",
        "            obs = self.normalize(obs)\n",
        "        else:\n",
        "            obs = self.normalize(np.array([obs]))[0]\n",
        "        if not return_info:\n",
        "            return obs\n",
        "        else:\n",
        "            return obs, info\n",
        "\n",
        "    def normalize(self, obs):\n",
        "        self.obs_rms.update(obs)\n",
        "        return (obs - self.obs_rms.mean) / np.sqrt(self.obs_rms.var + self.epsilon)\n",
        "\n",
        "\n",
        "class NormalizeReward(gym.core.Wrapper):\n",
        "    def __init__(\n",
        "        self,\n",
        "        env,\n",
        "        gamma=0.99,\n",
        "        epsilon=1e-8,\n",
        "    ):\n",
        "        super().__init__(env)\n",
        "        self.num_envs = getattr(env, \"num_envs\", 1)\n",
        "        self.is_vector_env = getattr(env, \"is_vector_env\", False)\n",
        "        self.return_rms = RunningMeanStd(shape=())\n",
        "        self.returns = np.zeros(self.num_envs)\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def step(self, action):\n",
        "        obs, rews, dones, infos = self.env.step(action)\n",
        "        if not self.is_vector_env:\n",
        "            rews = np.array([rews])\n",
        "        self.returns = self.returns * self.gamma + rews\n",
        "        rews = self.normalize(rews)\n",
        "        self.returns[dones] = 0.0\n",
        "        if not self.is_vector_env:\n",
        "            rews = rews[0]\n",
        "        return obs, rews, dones, infos\n",
        "\n",
        "    def normalize(self, rews):\n",
        "        self.return_rms.update(self.returns)\n",
        "        return rews / np.sqrt(self.return_rms.var + self.epsilon)"
      ],
      "metadata": {
        "id": "iVb5lsOBrBWz"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym_ple.make('Catcher-v0')"
      ],
      "metadata": {
        "id": "oiOkhb6wrH9z"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = env.reset()\n",
        "obs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KGwqMelrMZz",
        "outputId": "54a5aba4-4e09-4268-ad7f-7a097c068518"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.observation_space, env.action_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtvQtHSDrP9D",
        "outputId": "94a707b4-e8ec-4e66-b4d0-686f8d4372a1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Box(0, 255, (64, 64, 3), uint8), Discrete(3))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs = env.reset()\n",
        "\n",
        "for i in range(10):\n",
        "  obs, _, _, _ = env.step(env.action_space.sample())"
      ],
      "metadata": {
        "id": "OSWvXrkkrR3T"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(obs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "5RsLbKRWrUP7",
        "outputId": "7f2e1528-e67d-432b-aaaf-718eb4f7ed28"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3e67686910>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_environment(env_name):\n",
        "  env = gym_ple.make(env_name)\n",
        "  env = MaxAndSkipEnv(env)\n",
        "  env = WarpFrame(env, height=42, width=42)\n",
        "  env = TransformObservation(env, lambda x: x.swapaxes(-1, 0))\n",
        "  env.observation_space = gym.spaces.Box(low=0, high=255, shape=(1,42,42), dtype=np.float32)\n",
        "  env = NormalizeObservation(env)\n",
        "  env = NormalizeReward(env)\n",
        "  return env"
      ],
      "metadata": {
        "id": "AnRRw1wvrWB8"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepQLearning(LightningModule):\n",
        "\n",
        "  def __init__(self, env_name, policy=greedy, capacity=100_000, \n",
        "               batch_size=256, lr=1e-3, hidden_size=128, gamma=0.99, \n",
        "               loss_fn=F.smooth_l1_loss, optim=AdamW, samples_per_epoch=10_000, \n",
        "               sync_rate=10, a_start=0.5, a_end=0.0, a_last_episode=100,\n",
        "               b_start=0.4, b_end=1.0, b_last_episode=100, sigma=0.5):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.env = create_environment(env_name)\n",
        "\n",
        "    obs_size = self.env.observation_space.shape\n",
        "    n_actions = self.env.action_space.n\n",
        "\n",
        "    self.q_net = DQN(hidden_size, obs_size, n_actions, sigma)\n",
        "\n",
        "    # A copy that will be used to compute stable targets\n",
        "    # Will update the values in this copy every sync_rate epochs\n",
        "    self.target_q_net = copy.deepcopy(self.q_net) \n",
        "\n",
        "    self.policy = policy\n",
        "    self.buffer = ReplayBuffer(capacity=capacity)\n",
        "\n",
        "    self.save_hyperparameters()\n",
        "\n",
        "    while len(self.buffer) < self.hparams.samples_per_epoch:\n",
        "      print(f\"{len(self.buffer)} samples in experience buffer. Filling...\")\n",
        "      self.play_episode()\n",
        "\n",
        "  @torch.no_grad() # We have a policy\n",
        "  # If we dont include this, action will participate in the learning process\n",
        "  def play_episode(self, policy=None):\n",
        "    state = self.env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "      if policy:\n",
        "        action = policy(state, self.q_net)\n",
        "      else:\n",
        "        action = self.env.action_space.sample()\n",
        "      next_state, reward, done, info = self.env.step(action)\n",
        "      exp = (state, action, reward, done, next_state)\n",
        "      self.buffer.append(exp)\n",
        "      state = next_state\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.q_net(x)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    q_net_optimizer = self.hparams.optim(self.q_net.parameters(), \n",
        "                                         lr=self.hparams.lr)\n",
        "    return [q_net_optimizer] # We might have multiple neural networks, hence\n",
        "                             # multiple optimizers\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    dataset = RLDataset(self.buffer, self.hparams.samples_per_epoch)\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=self.hparams.batch_size\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    indices, weights, states, actions, rewards, dones, next_states = batch\n",
        "    weights = weights.unsqueeze(1)\n",
        "    actions = actions.unsqueeze(1)\n",
        "    rewards = rewards.unsqueeze(1)\n",
        "    dones = dones.unsqueeze(1)\n",
        "\n",
        "    # Gather on the first dimension, the values of the actions taken\n",
        "    state_action_values = self.q_net(states).gather(1, actions)\n",
        "\n",
        "    # DELETED\n",
        "    #next_action_values, _ = self.target_q_net(next_states).max(dim=1,\n",
        "    #                                                           keepdim=True)\n",
        "    # DELETED\n",
        "    \n",
        "    # ADDED\n",
        "    with torch.no_grad():\n",
        "      # Selects the action to be taken\n",
        "      _, next_actions = self.q_net(next_states).max(dim=1, keepdim=True)\n",
        "      # Estimates the value of those actions\n",
        "      next_action_values = self.target_q_net(next_states).gather(1, next_actions)\n",
        "      # ADDED\n",
        "      \n",
        "      # It will give estimated by default (the real result is 0.0, and we know this)\n",
        "      next_action_values[dones] = 0.0 \n",
        "\n",
        "    expected_state_action_values = rewards + self.hparams.gamma * next_action_values\n",
        "\n",
        "    # Compute the priorities and update\n",
        "    td_errors = (state_action_values - expected_state_action_values).abs().detach()\n",
        "\n",
        "    for idx, e in zip(indices, td_errors):\n",
        "      self.buffer.update(idx, e.cpu().item())\n",
        "\n",
        "    # Compute the weighted loss function\n",
        "    # reduction = 'none' because the shape of weights is (batch_size, 1)\n",
        "    loss = weights * self.hparams.loss_fn(state_action_values, expected_state_action_values, reduction='none')\n",
        "    loss = loss.mean()\n",
        "\n",
        "    self.log('episode/Q-error', loss)\n",
        "    return loss\n",
        "\n",
        "  def training_epoch_end(self, outputs):\n",
        "    # Decreasing as we go forward    \n",
        "    alpha = max(\n",
        "        self.hparams.a_end,\n",
        "        self.hparams.a_start - self.current_epoch / self.hparams.a_last_episode\n",
        "    )\n",
        "    beta = max(\n",
        "        self.hparams.b_end,\n",
        "        self.hparams.b_start - self.current_epoch / self.hparams.b_last_episode\n",
        "    )\n",
        "    self.buffer.alpha = alpha\n",
        "    self.buffer.beta = beta\n",
        "\n",
        "    self.play_episode(policy=self.policy)\n",
        "    # RecordStatistics keeps data in return_queue\n",
        "    self.log('episode/Return', self.env.unwrapped.game_state.score())\n",
        "\n",
        "    # The targets would be more stable after this\n",
        "    if self.current_epoch % self.hparams.sync_rate == 0:\n",
        "      self.target_q_net.load_state_dict(self.q_net.state_dict())"
      ],
      "metadata": {
        "id": "xhq3_yxOrdUr"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/lightning_logs/\n",
        "!rm -r /content/videos/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPXmdR6psDn0",
        "outputId": "66e73dab-14b2-462a-8a52-9a51324e60c6"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/videos/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir /content/lightning_logs/"
      ],
      "metadata": {
        "id": "DgQp8HdSsPgL"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo = DeepQLearning(\n",
        "    'Catcher-v0',\n",
        "    lr=5e-4,\n",
        "    hidden_size=512,\n",
        "    capacity=10_000,\n",
        "    sigma=0.5,\n",
        "    samples_per_epoch=1_000,\n",
        "    a_last_episode=1_200,\n",
        "    b_last_episode=1_200)\n",
        "\n",
        "trainer = Trainer(\n",
        "    gpus=num_gpus,\n",
        "    max_epochs=2_000,\n",
        "    log_every_n_steps=1\n",
        ")\n",
        "\n",
        "trainer.fit(algo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850,
          "referenced_widgets": [
            "74d5021f1dcf4d32900de5bafe64e4fe",
            "67a960dd90fd402aba3b901a236d3693",
            "7f04eb1c54bf45c0b531fc74d92110cb",
            "b82042eeb8864296a5ee3c1cc982b40f",
            "22b51320b16544a48351900f5694bf98",
            "6b10d7ce9f4346eab271614cf0815fda",
            "5b22f931325d43b6819f5287b5e99333",
            "a9fe6eb7e2d04fb3a3665f203312ac3b",
            "76ce04c73cec468589d5fa9348e79b6d",
            "ce6fb78e724b4e958ad4b4d8da47f7d9",
            "4cb940add6eb4d87a9d1dec1d5018042"
          ]
        },
        "id": "2dnX_fWesQka",
        "outputId": "2ca24f86-bec9-495d-b74d-51e711f9b7f1"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 samples in experience buffer. Filling...\n",
            "28 samples in experience buffer. Filling...\n",
            "65 samples in experience buffer. Filling...\n",
            "113 samples in experience buffer. Filling...\n",
            "157 samples in experience buffer. Filling...\n",
            "204 samples in experience buffer. Filling...\n",
            "242 samples in experience buffer. Filling...\n",
            "271 samples in experience buffer. Filling...\n",
            "315 samples in experience buffer. Filling...\n",
            "372 samples in experience buffer. Filling...\n",
            "434 samples in experience buffer. Filling...\n",
            "474 samples in experience buffer. Filling...\n",
            "503 samples in experience buffer. Filling...\n",
            "532 samples in experience buffer. Filling...\n",
            "561 samples in experience buffer. Filling...\n",
            "597 samples in experience buffer. Filling...\n",
            "624 samples in experience buffer. Filling...\n",
            "663 samples in experience buffer. Filling...\n",
            "700 samples in experience buffer. Filling...\n",
            "737 samples in experience buffer. Filling...\n",
            "775 samples in experience buffer. Filling...\n",
            "813 samples in experience buffer. Filling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/lightning_logs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name         | Type | Params\n",
            "--------------------------------------\n",
            "0 | q_net        | DQN  | 830 K \n",
            "1 | target_q_net | DQN  | 830 K \n",
            "--------------------------------------\n",
            "1.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.7 M     Total params\n",
            "6.641     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "840 samples in experience buffer. Filling...\n",
            "869 samples in experience buffer. Filling...\n",
            "899 samples in experience buffer. Filling...\n",
            "943 samples in experience buffer. Filling...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74d5021f1dcf4d32900de5bafe64e4fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-b44f22633f78>:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  state = torch.tensor([state]).to(device)\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:727: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = algo.env\n",
        "policy = algo.policy\n",
        "q_net = algo.q_net.cuda()\n",
        "frames = []\n",
        "\n",
        "for episode in range(10):\n",
        "  done = False\n",
        "  obs = env.reset()\n",
        "  while not done:\n",
        "    frames.append(env.render(mode='rgb_array'))\n",
        "    action = policy(obs, env, q_net)\n",
        "    obs, _, done, _ = env.step(action)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "-KCTSbLvsRvy",
        "outputId": "ce9d7f9c-9a3d-4953-cc94-b3fa489b881c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-818a19ab6b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mq_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_video(frames)"
      ],
      "metadata": {
        "id": "FryJhxbfsS6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKjP4r9ctI1v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}