{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOy4C2Y3YrceOMWDHPWtzdZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nimamt/machine_learning/blob/master/pytorch/PyTorchBuildingTheNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything is in namespace torch.nn   \n",
        "The NN is a \"nn.Module\" comprising other \"nn.Module\"s"
      ],
      "metadata": {
        "id": "zPogMxb-ivIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "04kae2xJijgC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxL8WbQZi_tW",
        "outputId": "ff7ec7f1-2678-4c86-ba7e-627945340413"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize the neural network layers in __init__  \n",
        "Every nn.Module subclass implements the operations on input data in the forward method."
      ],
      "metadata": {
        "id": "J0A6gm2SjIt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "-WuedkVGjEDx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create an instance of NeuralNetwork, and move it to the device, and print its structure."
      ],
      "metadata": {
        "id": "bfyYK9UzjZ_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "246Qlz2xjMtz",
        "outputId": "a64a2bc1-3267-4a57-ca2f-23bfaedba420"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the model, we pass it the input data. This executes the modelâ€™s forward, along with some background operations. Do not call model.forward() directly!\n",
        "\n",
        "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output. . We get the prediction probabilities by passing it through an instance of the nn.Softmax module."
      ],
      "metadata": {
        "id": "mH1LEuVJjpar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Logits: {logits}\")\n",
        "print(f\"Pred_probab: {pred_probab}\")\n",
        "\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT9EJylOjY5e",
        "outputId": "a7b95e32-b511-4b60-9048-494ea8078e31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits: tensor([[-0.0265,  0.0334,  0.0545,  0.0365, -0.0606, -0.1254, -0.1351, -0.0455,\n",
            "          0.0274,  0.0093]], grad_fn=<AddmmBackward0>)\n",
            "Pred_probab: tensor([[0.0995, 0.1056, 0.1079, 0.1059, 0.0961, 0.0901, 0.0892, 0.0976, 0.1050,\n",
            "         0.1031]], grad_fn=<SoftmaxBackward0>)\n",
            "Predicted class: tensor([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IroNCP6lj4ZU",
        "outputId": "29e20462-287f-4db9-f064-64d73ff5c257"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkcqGn01kTC7",
        "outputId": "cb340cb1-60e0-4440-e3f3-b1e895563a6d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbawWxZWkZyR",
        "outputId": "59abbcc9-1633-4c91-de00-1c9aab3be93a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3-VssYgkhEo",
        "outputId": "77d25b60-8556-415a-c4cf-37a064aa0a38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[-0.1100, -0.1732,  0.7788, -0.1063,  0.0276, -0.2213,  0.2206, -0.0509,\n",
            "         -0.2799, -0.3075,  0.1831, -0.4474, -0.1461,  0.3429, -0.3700,  0.3695,\n",
            "          0.3400, -0.1779,  0.2926,  0.3530],\n",
            "        [-0.1210, -0.1663,  0.5153, -0.4236,  0.2766, -0.2771,  0.0650,  0.1930,\n",
            "         -0.0800, -0.0709,  0.5352, -0.5092, -0.1253,  0.3392, -0.8086,  0.1576,\n",
            "          0.0481, -0.2922,  0.0989,  0.2460],\n",
            "        [ 0.0541, -0.3886,  0.6981, -0.0341,  0.0348, -0.3995,  0.0525, -0.2674,\n",
            "         -0.2706, -0.2987,  0.1123, -0.4461, -0.2327,  0.2846, -0.8422, -0.2055,\n",
            "          0.4597, -0.2094,  0.1325,  0.1265]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.0000, 0.0000, 0.7788, 0.0000, 0.0276, 0.0000, 0.2206, 0.0000, 0.0000,\n",
            "         0.0000, 0.1831, 0.0000, 0.0000, 0.3429, 0.0000, 0.3695, 0.3400, 0.0000,\n",
            "         0.2926, 0.3530],\n",
            "        [0.0000, 0.0000, 0.5153, 0.0000, 0.2766, 0.0000, 0.0650, 0.1930, 0.0000,\n",
            "         0.0000, 0.5352, 0.0000, 0.0000, 0.3392, 0.0000, 0.1576, 0.0481, 0.0000,\n",
            "         0.0989, 0.2460],\n",
            "        [0.0541, 0.0000, 0.6981, 0.0000, 0.0348, 0.0000, 0.0525, 0.0000, 0.0000,\n",
            "         0.0000, 0.1123, 0.0000, 0.0000, 0.2846, 0.0000, 0.0000, 0.4597, 0.0000,\n",
            "         0.1325, 0.1265]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ],
      "metadata": {
        "id": "GTjvjdPwkojE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------- dim = 1\n",
        "\n",
        "|  \n",
        "|  \n",
        "|  \n",
        "|  \n",
        "|  \n",
        "dim = 0"
      ],
      "metadata": {
        "id": "JYIZ7KGYmcJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ],
      "metadata": {
        "id": "mNbIbu0Qk46Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a5kEG-clVVR",
        "outputId": "f1151fa5-2a79-4273-e072-39818d987094"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1034, 0.1184, 0.1028, 0.1198, 0.1103, 0.1057, 0.0669, 0.0903, 0.0820,\n",
              "         0.1004],\n",
              "        [0.1036, 0.1006, 0.0863, 0.0984, 0.1212, 0.1004, 0.0760, 0.1007, 0.0956,\n",
              "         0.1172],\n",
              "        [0.1015, 0.1042, 0.1016, 0.1095, 0.1012, 0.1007, 0.0819, 0.0991, 0.0984,\n",
              "         0.1019]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ogDBI_clW08",
        "outputId": "32015b96-c64e-485a-fce8-2d130b6fc689"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0088, -0.0004, -0.0163,  ...,  0.0263, -0.0165, -0.0068],\n",
            "        [-0.0196, -0.0255,  0.0156,  ...,  0.0010, -0.0072,  0.0049]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0248, 0.0140], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0026, -0.0026, -0.0149,  ...,  0.0081,  0.0069,  0.0223],\n",
            "        [ 0.0089, -0.0233,  0.0340,  ...,  0.0006, -0.0371,  0.0355]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0199, -0.0178], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0290, -0.0353, -0.0311,  ...,  0.0062, -0.0415,  0.0410],\n",
            "        [-0.0390,  0.0254, -0.0377,  ...,  0.0102, -0.0299, -0.0196]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0316, -0.0130], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9w47f7pSmogy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}